# -*- coding: utf-8 -*-
# Author: Konstantinos Gallos <kggallos@gmail.com>
# License: Apache-2.0 License
"""
This code is adapted from [pythresh] by [KulikDM]
Original source: [https://github.com/KulikDM/pythresh]
"""

import inspect
import pandas as pd
import numpy as np
import argparse, time
import scipy.stats as stats

from TSB_AD.evaluation.metrics import get_metrics
from TSB_AD.utils.slidingWindows import find_length_rank

from .thresholding_utils import check_scores, normalize

class QMCD():
    """QMCD class for Quasi-Monte Carlo Discrepancy thresholder.

       Use the quasi-Monte Carlo discrepancy to evaluate a non-parametric means
       to threshold scores generated by the decision_scores where outliers
       are set to any value beyond and percentile or quantile of one minus the
       discrepancy. See :cite:`iouchtchenko2019qmcd` for details.

       Parameters
       ----------

       method : {'CD', 'WD', 'MD', 'L2-star'}, optional (default='WD')
            Type of discrepancy

            - 'CD':      Centered Discrepancy
            - 'WD':      Wrap-around Discrepancy
            - 'MD':      Mix between CD/WD
            - 'L2-star': L2-star discrepancy

       lim : {'Q', 'P'}, optional (default='P')
            Filtering method to threshold scores using 1 - discrepancy

            - 'Q': Use quantile limiting
            - 'P': Use percentile limiting

       random_state : int, optional (default=1234)
            Random seed for the random number generators of the thresholders. Can also
            be set to None.

       Attributes
       ----------

        threshold_ : float
            The threshold value that separates inliers from outliers.

        decision_scores_: ndarray of shape (n_samples,) #TODO
            Not actually used, present for API consistency by convention.
            It contains 0s and 1s because this is a thresholding method.

       Notes
       -----

       For the QMCD method it is assumed that the decision scores are pseudo-random
       values within a distribution :math:`M`. "Quasi-random" sequences, which are
       numbers that are better equidistributed for :math:`M` than pseudo-random numbers
       are used to calculate the decision scores discrepancy value.

       The discrepancy value is a uniformity criterion which is used to assess the space
       filling of a number of samples in a hypercube. It quantifies the distance between
       the continuous uniform distribution on a hypercube and the discrete uniform distribution
       on distinct sample points. Therefore, lower values mean better coverage of the parameter
       space.

       The QMCD method utilizes the discrepancy value by assuming that when it is at its lowest
       value (0) the "quasi-random" generated sequences and the decision scores are equally
       equidistributed across :math:`M`. Outliers are assumed to solely raise the discrepancy
       value. And therefore, the contamination of the dataset can be set as one minus the
       discrepancy.
    """


    def __init__(self, method='WD', lim='P', 
                 random_state=1234, normalize=True):

        self.method = method
        self.lim = lim
        self.random_state = random_state
        self.normalize = normalize

    def fit(self, X, y=None):
        """Fit detector. y is ignored in unsupervised methods.

        Parameters
        ----------
        X : numpy array of shape (n_samples, n_features)
            The input samples.

        y : Ignored
            Not used, present for API consistency by convention.

        Returns
        -------
        self : object
            Fitted estimator.
        """
        pass

    def decision_function(self, X):
        """    
        Not used, present for API consistency by convention.
        """
        pass
        
    def predict(self, X):
        """
        Predict anomalies in a batch of data points.

        Parameters
        ----------
        X : numpy array of shape (n_samples,)
            The input data points.

        Returns
        -------
        preds : numpy array of shape (n_samples,)
            Predictions (1 for anomaly, 0 for normal).
        """
        n_samples, n_features = X.shape

        X = check_scores(X, random_state=self.random_state)

        if self.normalize: X = normalize(X)

        # Get the quasi Monte-Carlo discrepancy of the labels
        disc = stats.qmc.discrepancy(
            X.reshape(-1, 1), method=self.method)

        # Set the limit to either the quantile or percentile of 1-discrepancy
        if self.lim == 'Q':

            limit = np.quantile(X, 1.0-disc)

        elif self.lim == 'P':

            arg_map = {'old': 'interpolation', 'new': 'method'}
            arg_name = (arg_map['new'] if 'method' in
                        inspect.signature(np.percentile).parameters
                        else arg_map['old'])

            limit = np.percentile(X, (1.0-disc) *
                                  100, **{arg_name: 'midpoint'})

        self.threshold_ = limit

        preds = np.zeros(n_samples, dtype=int)
        preds[X >= limit] = 1

        return preds



if __name__ == '__main__':

    Start_T = time.time()
    ## ArgumentParser
    parser = argparse.ArgumentParser(description='Running QMCD')
    parser.add_argument('--filename', type=str, default='001_NAB_id_1_Facility_tr_1007_1st_2014.csv')
    parser.add_argument('--data_direc', type=str, default='Datasets/TSB-AD-U/')
    parser.add_argument('--AD_Name', type=str, default='QMCD')
    args = parser.parse_args()

    Custom_AD_HP = {
        'random_state': 1234,   # not related to method itself, but to formatting input
        'method': 'WD', 
        'lim':'P'
    }

    df = pd.read_csv(args.data_direc + args.filename).dropna()
    data = df.iloc[:, 0:-1].values.astype(float)
    label = df['Label'].astype(int).to_numpy()
    print('data: ', data.shape)
    print('label: ', label.shape)

    slidingWindow = find_length_rank(data, rank=1)

    methods = ['CD', 'WD', 'MD', 'L2-star']
    for method in methods:
        print(f"\nRunning method: {method}")
        Custom_AD_HP['method'] = method
        clf = QMCD(**Custom_AD_HP)
        output = clf.predict(data)
        pred = output   # output has already the predictions
        evaluation_result = get_metrics(output, label, slidingWindow=slidingWindow, pred=pred)
        print('Evaluation Result: ', evaluation_result)

    Custom_AD_HP['lim'] = 'Q'
    clf = QMCD(**Custom_AD_HP)
    output = clf.predict(data)
    pred = output
    evaluation_result = get_metrics(output, label, slidingWindow=slidingWindow, pred=pred)
    print('Evaluation Result: ', evaluation_result)
