# -*- coding: utf-8 -*-
# Author: Konstantinos Gallos <kggallos@gmail.com>
# License: Apache-2.0 License
"""
This code is adapted from [pythresh] by [KulikDM]
Original source: [https://github.com/KulikDM/pythresh]
"""

import pandas as pd
import numpy as np
import scipy.stats as stats
from scipy.special import erfc
import argparse, time

from TSB_AD.evaluation.metrics import get_metrics
from TSB_AD.utils.slidingWindows import find_length_rank
from TSB_AD.models.base import BaseDetector

from .thresholding_utils import check_scores, normalize

class CHAU(BaseDetector):
    r"""CHAU class for Chauvenet's criterion thresholder.

       Use the Chauvenet's criterion to evaluate a non-parametric
       means to threshold scores generated by the decision_scores
       where outliers are set to any value below the Chauvenet's
       criterion. See :cite:`bolshev2016chau` for details

       Parameters
       ----------

        method : {'mean', 'median', 'gmean'}, optional (default='mean')
            Calculate the area normal to distance using a scaler

            - 'mean':  Construct a scaler with the the mean of the scores
            - 'median: Construct a scaler with the the median of the scores
            - 'gmean': Construct a scaler with the geometric mean of the scores

        random_state : int, optional (default=1234)
            Random seed for the random number generators of the thresholders.
            Can also be set to None.

        Attributes
        ----------
        threshold_ : float
            The threshold value that separates inliers from outliers.

        decision_scores_: ndarray of shape (n_samples,) #TODO
            Not actually used, present for API consistency by convention.
                It contains 0s and 1s because this is a thresholding method.

       Notes
       -----

       The Chauvenet's criterion for a one tail of a distribution is defined
       as follows:

       .. math::

           D_{\mathrm{max}}>Z \mathrm{,}

       where :math:`D_{\mathrm{max}}` is the bounds of the probability band
       around the mean given by,

       .. math::

           D_{\mathrm{max}} = \lvert norm.ppf(Pz) \rvert \mathrm{,}

       where this bounds is equal to the inverse of a cumulative distribution function
       for a probability of one of the tails of the normal distribution, and :math:`P_z`
       is therefore defined as,

       .. math::

           P_z = \frac{1}{4n} \mathrm{,}

       with :math:`n` being the number of samples in the decision scores. Finally the z-score
       can be calculated as follows:

       .. math::

           Z = \frac{x-\bar{x}}{\sigma} \mathrm{,}

       with :math:`\bar{x}` as the mean and :math:`\sigma` the standard deviation
       of the decision scores.

       CHAU employs variants of the classical Chauvenet's criterion as the mean can be
       replaced with the geometric mean or the median.

       Any z-score greater than the Chauvenet's criterion is considered an outlier.

    """

    def __init__(self, method='mean', random_state=1234, normalize=True):
        super().__init__()
        stat = {'mean': np.mean, 'median': np.median, 'gmean': stats.gmean}
        self.method = stat[method]
        self.random_state = random_state
        self.normalize = normalize

    def fit(self, X, y=None):
        """Fit detector. y is ignored in unsupervised methods.

        Parameters
        ----------
        X : numpy array of shape (n_samples, n_features)
            The input samples.

        y : Ignored
            Not used, present for API consistency by convention.

        Returns
        -------
        self : object
            Fitted estimator.
        """
        pass

    def decision_function(self, X):
        """    
        Not used, present for API consistency by convention.
        """
        pass
        
    def predict(self, X):
        """
        Predict anomalies in a batch of data points.

        Parameters
        ----------
        X : numpy array of shape (n_samples,)
            The input data points.

        Returns
        -------
        preds : numpy array of shape (n_samples,)
            Predictions (1 for anomaly, 0 for normal).
        """
        n_samples, n_features = X.shape

        X = check_scores(X, random_state=self.random_state)

        if self.normalize: X = normalize(X)

        # Calculate Chauvenet's criterion for one tail
        Pz = 1/(4*len(X))
        criterion = 1/abs(stats.norm.ppf(Pz))

        # Get area normal to distance
        prob = erfc(np.abs(X-self.method(X)) /
                    X.std()/2.0**0.5)

        self.threshold_ = criterion * (1-np.min(prob))/np.max(prob)

        preds = np.zeros(n_samples, dtype=int)
        preds[X >= self.threshold_] = 1
        preds = 1 - preds

        return preds


if __name__ == '__main__':

    Start_T = time.time()
    ## ArgumentParser
    parser = argparse.ArgumentParser(description='Running MAD')
    parser.add_argument('--filename', type=str, default='001_NAB_id_1_Facility_tr_1007_1st_2014.csv')
    parser.add_argument('--data_direc', type=str, default='Datasets/TSB-AD-U/')
    parser.add_argument('--AD_Name', type=str, default='MAD')
    args = parser.parse_args()

    Custom_AD_HP = {
        'random_state': 1234,   # not related to method itself, but to formatting input
    }

    df = pd.read_csv(args.data_direc + args.filename).dropna()
    data = df.iloc[:, 0:-1].values.astype(float)
    label = df['Label'].astype(int).to_numpy()
    print('data: ', data.shape)
    print('label: ', label.shape)

    slidingWindow = find_length_rank(data, rank=1)
    train_index = args.filename.split('.')[0].split('_')[-3]
    data_train = data[:int(train_index), :]
    data_test = data[int(train_index):, :]
    label_test = label[int(train_index):]

    start_time = time.time()

    print("------- ON TEST DATA -------")
    clf = CHAU()
    # clf.fit(data_train)
    output = clf.predict(data_test)
    pred = output   # output has already the predictions

    end_time = time.time()
    run_time = end_time - start_time

    evaluation_result = get_metrics(output, label_test, slidingWindow=slidingWindow, pred=pred)
    print('Evaluation Result: ', evaluation_result)

    ####!
    print("------- ON WHOLE DATA -------")
    clf = CHAU()
    # clf.fit(data)
    output = clf.predict(data)
    pred = output
    evaluation_result = get_metrics(output, label, slidingWindow=slidingWindow, pred=pred)
    print('Evaluation Result: ', evaluation_result)
