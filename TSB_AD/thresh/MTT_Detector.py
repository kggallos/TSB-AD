# -*- coding: utf-8 -*-
# Author: Konstantinos Gallos <kggallos@gmail.com>
# License: Apache-2.0 License
"""
This code is adapted from [pythresh] by [KulikDM]
Original source: [https://github.com/KulikDM/pythresh]
"""

import pandas as pd
import numpy as np
import scipy.stats as stats
import argparse, time

from TSB_AD.evaluation.metrics import get_metrics
from TSB_AD.utils.slidingWindows import find_length_rank

from .thresholding_utils import check_scores, normalize

class MTT():
    r"""MTT class for Modified Thompson Tau test thresholder.

       Use the modified Thompson Tau test to evaluate a non-parametric means
       to threshold scores generated by the decision_scores where outliers
       are set to any value beyond the smallest outlier detected by the test.
       See :cite:`rengasamy2020mtt` for details.

       Parameters
       ----------

       alpha : float, optional (default=0.99)
            Confidence level corresponding to the t-Student distribution map to sample

       random_state : int, optional (default=1234)
            Random seed for the random number generators of the thresholders. Can also
            be set to None.

       Attributes
       ----------

        threshold_ : float
            The threshold value that separates inliers from outliers.

        decision_scores_: ndarray of shape (n_samples,) #TODO
            Not actually used, present for API consistency by convention.
            It contains 0s and 1s because this is a thresholding method.

       Notes
       -----

       The Modified Thompson Tau test is a modified univariate t-test that eliminates outliers
       that are more than a number of standard deviations away from the mean. This method is
       done iteratively with the Tau critical value being recalculated after each outlier removal
       until the dataset no longer has data points that fall outside of the criterion. The Tau
       critical value can be obtained by,

       .. math::

           \tau = \frac{t \cdot (n-1)}{\sqrt{n}\sqrt{n-2+t^2}}  \mathrm{,}

       where :math:`n` is the number of data points and :math:`t` is the student t-value

    """

    def __init__(self, alpha=0.99, random_state=1234, normalize=True):

        self.alpha = alpha
        self.random_state = random_state
        self.normalize = normalize

    def fit(self, X, y=None):
        """Fit detector. y is ignored in unsupervised methods.

        Parameters
        ----------
        X : numpy array of shape (n_samples, n_features)
            The input samples.

        y : Ignored
            Not used, present for API consistency by convention.

        Returns
        -------
        self : object
            Fitted estimator.
        """
        pass

    def decision_function(self, X):
        """    
        Not used, present for API consistency by convention.
        """
        pass
        
    def predict(self, X):
        """
        Predict anomalies in a batch of data points.

        Parameters
        ----------
        X : numpy array of shape (n_samples,)
            The input data points.

        Returns
        -------
        preds : numpy array of shape (n_samples,)
            Predictions (1 for anomaly, 0 for normal).
        """
        n_samples, n_features = X.shape

        X = check_scores(X, random_state=self.random_state)

        if self.normalize: X = normalize(X)

        arr = np.sort(X.copy())

        limit = 1.1

        while True:

            # Calculate the rejection threshold
            n = len(arr)
            t = stats.t.ppf(self.alpha, df=n-2)
            thres = (t * (n - 1))/(np.sqrt(n) * np.sqrt(n - 2 + t**2))
            delta = np.abs(arr[-1] - arr.mean())/arr.std()

            if delta > thres:
                limit = arr[-1]
                arr = np.delete(arr, n-1)

            else:
                break

        self.threshold_ = limit

        preds = np.zeros(n_samples, dtype=int)
        preds[X >= limit] = 1

        return preds


if __name__ == '__main__':

    Start_T = time.time()
    ## ArgumentParser
    parser = argparse.ArgumentParser(description='Running MTT')
    parser.add_argument('--filename', type=str, default='001_NAB_id_1_Facility_tr_1007_1st_2014.csv')
    parser.add_argument('--data_direc', type=str, default='Datasets/TSB-AD-U/')
    parser.add_argument('--AD_Name', type=str, default='MTT')
    args = parser.parse_args()

    # multivariate
    # parser.add_argument('--filename', type=str, default='057_SMD_id_1_Facility_tr_4529_1st_4629.csv')
    # parser.add_argument('--data_direc', type=str, default='Datasets/TSB-AD-M/')

    Custom_AD_HP = {
        'random_state': 1234,   # not related to method itself, but to formatting input
        'alpha': 0.99,
    }

    df = pd.read_csv(args.data_direc + args.filename).dropna()
    data = df.iloc[:, 0:-1].values.astype(float)
    label = df['Label'].astype(int).to_numpy()
    print('data: ', data.shape)
    print('label: ', label.shape)

    slidingWindow = find_length_rank(data, rank=1)

    clf = MTT(**Custom_AD_HP)
    output = clf.predict(data)
    pred = output
    evaluation_result = get_metrics(output, label, slidingWindow=slidingWindow, pred=pred)
    print('Evaluation Result: ', evaluation_result)
