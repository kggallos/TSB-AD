# -*- coding: utf-8 -*-
# Author: Konstantinos Gallos <kggallos@gmail.com>
# License: Apache-2.0 License
"""
This code is adapted from [pythresh] by [KulikDM]
Original source: [https://github.com/KulikDM/pythresh]
"""

import pandas as pd
import numpy as np
from scipy import signal
from scipy.ndimage import gaussian_filter
import argparse, time

from TSB_AD.evaluation.metrics import get_metrics
from TSB_AD.utils.slidingWindows import find_length_rank

from .thresholding_utils import check_scores, normalize

class FILTER():
    """FILTER class for Filtering based thresholders.

       Use the filtering based methods to evaluate a non-parametric means
       to threshold scores generated by the decision_scores where outliers
       are set to any value beyond the maximum filter value.
       See :cite:`hashemi2019filter` for details.

       Parameters
       ----------

       method : {'gaussian', 'savgol', 'hilbert', 'wiener', 'medfilt', 'decimate','detrend', 'resample'}, optional (default='savgol')
            Method to filter the scores

            - 'gaussian': use a gaussian based filter
            - 'savgol':   use the savgol based filter
            - 'hilbert':  use the hilbert based filter
            - 'wiener':   use the wiener based filter
            - 'medfilt:   use a median based filter
            - 'decimate': use a decimate based filter
            - 'detrend':  use a detrend based filter
            - 'resample': use a resampling based filter

       sigma : int, optional (default='auto')
            Variable specific to each filter type, default sets sigma to len(scores)*np.std(scores)

            - 'gaussian': standard deviation for Gaussian kernel
            - 'savgol':   savgol filter window size
            - 'hilbert':  number of Fourier components
            - 'medfilt:   kernel size
            - 'decimate': downsampling factor
            - 'detrend':  number of break points
            - 'resample': resampling window size

       random_state : int, optional (default=1234)
            Random seed for the random number generators of the thresholders. Can also
            be set to None.

       Attributes
       ----------

        threshold_ : float
            The threshold value that separates inliers from outliers.

        decision_scores_: ndarray of shape (n_samples,) #TODO
            Not actually used, present for API consistency by convention.
            It contains 0s and 1s because this is a thresholding method.
    """


    def __init__(self, method='savgol', sigma='auto', 
                 random_state=1234, normalize=True):

        super().__init__()
        self.method = method
        self.method_funcs = {'gaussian': self._GAU_fltr, 'savgol': self._SAV_fltr,
                             'hilbert': self._HIL_fltr, 'wiener': self._WIE_fltr,
                             'medfilt': self._MED_fltr, 'decimate': self._DEC_fltr,
                             'detrend': self._DET_fltr, 'resample': self._RES_fltr}

        self.sigma = sigma
        self.random_state = random_state
        self.normalize = normalize

    def fit(self, X, y=None):
        """Fit detector. y is ignored in unsupervised methods.

        Parameters
        ----------
        X : numpy array of shape (n_samples, n_features)
            The input samples.

        y : Ignored
            Not used, present for API consistency by convention.

        Returns
        -------
        self : object
            Fitted estimator.
        """
        pass

    def decision_function(self, X):
        """    
        Not used, present for API consistency by convention.
        """
        pass
        
    def predict(self, X):
        """
        Predict anomalies in a batch of data points.

        Parameters
        ----------
        X : numpy array of shape (n_samples,)
            The input data points.

        Returns
        -------
        preds : numpy array of shape (n_samples,)
            Predictions (1 for anomaly, 0 for normal).
        """
        n_samples, n_features = X.shape

        X = check_scores(X, random_state=self.random_state)

        if self.normalize: X = normalize(X)

        # Get sigma variables for various applications for each filter
        sig = (len(X)*np.std(X) if self.sigma == 'auto'
               else self.sigma)

        # Filter scores
        fltr = self.method_funcs[str(self.method)](X, sig)
        limit = np.max(fltr)

        self.threshold_ = limit

        preds = np.zeros(n_samples, dtype=int)
        preds[X >= self.threshold_] = 1

        return preds

    def _GAU_fltr(self, decision, sig):
        """Gaussian filter scores."""

        return gaussian_filter(decision, sigma=sig)

    def _SAV_fltr(self, decision, sig):
        """Savgol filter scores."""

        sig = round(0.5*sig) if self.sigma == 'auto' else sig

        sig = sig+1 if sig % 2 == 0 else sig

        return signal.savgol_filter(decision, window_length=round(sig),
                                    polyorder=1)

    def _HIL_fltr(self, decision, sig):
        """Hilbert filter scores."""

        return signal.hilbert(decision, N=round(sig))

    def _WIE_fltr(self, decision, sig):
        """Wiener filter scores."""

        return signal.wiener(decision, mysize=len(decision))

    def _MED_fltr(self, decision, sig):
        """Medfilt filter scores."""

        sig = round(sig)

        sig = sig+1 if sig % 2 == 0 else sig

        return signal.medfilt(decision, kernel_size=[sig])

    def _DEC_fltr(self, decision, sig):
        """Decimate filter scores."""

        return signal.decimate(decision, q=round(sig), ftype='fir')

    def _DET_fltr(self, decision, sig):
        """Detrend filter scores."""

        return signal.detrend(decision, bp=np.linspace(0, len(decision)-1,
                                                       round(sig)).astype(int))

    def _RES_fltr(self, decision, sig):
        """Resampling filter scores."""

        sig = np.sqrt(sig) if self.sigma == 'auto' else sig

        return signal.resample(decision, num=round(np.sqrt(len(decision))),
                               window=round(sig))

if __name__ == '__main__':

    Start_T = time.time()
    ## ArgumentParser
    parser = argparse.ArgumentParser(description='Running FILTER')
    parser.add_argument('--filename', type=str, default='001_NAB_id_1_Facility_tr_1007_1st_2014.csv')
    parser.add_argument('--data_direc', type=str, default='Datasets/TSB-AD-U/')
    parser.add_argument('--AD_Name', type=str, default='FILTER')
    args = parser.parse_args()

    # multivariate
    # parser.add_argument('--filename', type=str, default='057_SMD_id_1_Facility_tr_4529_1st_4629.csv')
    # parser.add_argument('--data_direc', type=str, default='Datasets/TSB-AD-M/')

    Custom_AD_HP = {
        'random_state': 1234,   # not related to method itself, but to formatting input
    }

    df = pd.read_csv(args.data_direc + args.filename).dropna()
    data = df.iloc[:, 0:-1].values.astype(float)
    label = df['Label'].astype(int).to_numpy()
    print('data: ', data.shape)
    print('label: ', label.shape)

    slidingWindow = find_length_rank(data, rank=1)

    methods = ['gaussian', 'savgol', 'hilbert', 'wiener', 'medfilt', 'decimate','detrend', 'resample']
    for method in methods:
        print(f"\nRunning method: {method}")
        Custom_AD_HP['method'] = method
        clf = FILTER(**Custom_AD_HP)
        output = clf.predict(data)
        pred = output
        evaluation_result = get_metrics(output, label, slidingWindow=slidingWindow, pred=pred)
        print('Evaluation Result: ', evaluation_result)
